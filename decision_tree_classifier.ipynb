{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import copy\n",
    "import graphviz\n",
    "import featureSelection\n",
    "import time\n",
    "\n",
    "from scipy.stats import mode\n",
    "from sklearn.datasets import fetch_rcv1\n",
    "from scipy.sparse import csc_matrix, csr_matrix, find\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.sparse import isspmatrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def __init__(self):\n",
    "        self.max_depth = None\n",
    "        self.max_n_nodes = None\n",
    "        self.current_depth = 0\n",
    "        self.idx = 0\n",
    "        self.node_count = 0\n",
    "        self.Y_pred = None\n",
    "        self.all_nodes = []\n",
    "        self.all_edges = []\n",
    "        self.stop_condition = None\n",
    "        self.issparse = False\n",
    "        self.TPR = []\n",
    "        self.FPR = []\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        self.node=Node(parent=None, used_features=[], depth=1, idx=0, size=X.shape[0])\n",
    "        if isspmatrix(X):\n",
    "            self.issparse = True\n",
    "        self.rpart(X, Y, self.node)\n",
    "    \n",
    "    def rpart(self, X, Y, parent):\n",
    "        if X.shape[1] == len(parent.used_features):\n",
    "            return\n",
    "        ginigain = np.zeros(X.shape[1])\n",
    "        if self.issparse:\n",
    "            for i in range(X.shape[1]):\n",
    "                if i not in parent.used_features:\n",
    "                    p = featureSelection.freq2(X[:, i], Y, True)\n",
    "                    ginigain[i] = featureSelection.ginigain_fun(p)\n",
    "            if np.all(np.isnan(ginigain)):\n",
    "                return\n",
    "            best_split = np.nanargmax(ginigain)\n",
    "            ind1 = X[:, best_split].nonzero()[0]\n",
    "            ind0 = np.setdiff1d(range(X.shape[0]), ind1)\n",
    "            Xl = X[ind0, :]\n",
    "            Xr = X[ind1, :]\n",
    "            Yl = Y[ind0]\n",
    "            Yr = Y[ind1]\n",
    "            parent.feature = best_split\n",
    "        else:\n",
    "            for idx, column in enumerate(X):\n",
    "                if idx not in parent.used_features:\n",
    "                    xi = X[column]\n",
    "                    p = featureSelection.freq2(xi, Y, True)\n",
    "                    ginigain[idx] = featureSelection.ginigain_fun(p)\n",
    "            best_split = np.argmax(ginigain)\n",
    "            Xl = X[X.iloc[:, best_split] == True]\n",
    "            Xr = X[X.iloc[:, best_split] == False]\n",
    "            Yl = Y[X.iloc[:, best_split] == True]\n",
    "            Yr = Y[X.iloc[:, best_split] == False]\n",
    "            parent.feature = Xl.columns[best_split]\n",
    "\n",
    "        parent.pi = featureSelection.freq(Y, True)\n",
    "        used_features = copy.copy(parent.used_features)\n",
    "        used_features.append(best_split)  \n",
    "\n",
    "        self.idx += 1\n",
    "        parent.left = Node(parent, used_features, parent.depth + 1, self.idx, Xl.shape[0])\n",
    "\n",
    "        self.idx += 1\n",
    "        parent.right = Node(parent, used_features, parent.depth + 1, self.idx, Xr.shape[0])\n",
    "        if not self.StopCondition(Y, Yr, parent.depth + 1):\n",
    "            self.rpart(Xr, Yr, parent.right)\n",
    "        else:\n",
    "            if self.issparse:\n",
    "                if Yr.nonzero()[0].shape[0] / Xr.shape[0] >= 0.4:\n",
    "                    parent.right.leaf_val = 1\n",
    "                else:\n",
    "                    parent.right.leaf_val = 0\n",
    "            else:\n",
    "                parent.right.leaf_val = mode(Yr)[0]\n",
    "        if not self.StopCondition(Y, Yl, parent.depth + 1):\n",
    "            self.rpart(Xl, Yl, parent.left)\n",
    "        else:\n",
    "            if self.issparse:\n",
    "                if Yl.nonzero()[0].shape[0] / Xl.shape[0] >= 0.5:\n",
    "                    parent.left.leaf_val = 1\n",
    "                else:\n",
    "                    parent.left.leaf_val = 0\n",
    "            else:\n",
    "                parent.left.leaf_val = mode(Yl)[0]\n",
    "                                                \n",
    "    def StopCondition(self, Y, Y_child, depth):\n",
    "        if self.issparse:\n",
    "            if self.stop_condition == 'depth':\n",
    "                if depth >= self.max_depth:\n",
    "                    return True\n",
    "            else:\n",
    "                if self.idx >= self.max_n_nodes:\n",
    "                    return True\n",
    "            return False\n",
    "        name_Y, pi_Y = featureSelection.freq(Y, True)\n",
    "        name_Y_child, pi_Y_child = featureSelection.freq(Y_child, True)\n",
    "        if self.stop_condition == 'depth':\n",
    "            if depth == self.max_depth or len(name_Y_child) <= 1 :\n",
    "                return True\n",
    "        elif self.stop_condition == 'n_nodes':\n",
    "            if self.max_n_nodes >= self.idx or len(name_Y_child) <= 1 :\n",
    "                return True\n",
    "        else:\n",
    "            diff = np.setdiff1d(name_Y, name_Y_child)\n",
    "            pi_Y_child_whole = np.zeros_like(pi_Y)\n",
    "            j = 0\n",
    "            for i, name in enumerate(name_Y):\n",
    "                if name not in diff:\n",
    "                    pi_Y_child_whole[i] = pi_Y_child[j]\n",
    "                    j += 1\n",
    "            crosstab = pd.crosstab(pi_Y, pi_Y_child_whole)\n",
    "            chi2, p_value, degrees_of_freedom, expected_frequencies = chi2_contingency(crosstab)\n",
    "            if p_value > 0.3 or len(name_Y_child) <= 1:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.issparse:\n",
    "            self.Y_pred = []\n",
    "            for xi in X:\n",
    "                self.ppart_sparse(xi, self.node)\n",
    "        else:\n",
    "            self.Y_pred = np.zeros(X.shape[0], dtype=object)\n",
    "            self.ppart(X, self.node, X)\n",
    "        \n",
    "    def ppart_sparse(self, x, node):\n",
    "        if node.leaf_val != None:\n",
    "            self.Y_pred.append(node.leaf_val)\n",
    "        else:\n",
    "            if x[:, node.feature] == 1:\n",
    "                self.ppart_sparse(x, node.right)\n",
    "            else:\n",
    "                self.ppart_sparse(x, node.left)\n",
    "                \n",
    "    def ppart(self, X, node, mainX):\n",
    "        if node.leaf_val != None:\n",
    "            idx_X = [] \n",
    "            for idx, row_mainX in enumerate(mainX.T):\n",
    "                for rowX in X.T:\n",
    "                    if rowX == row_mainX:\n",
    "                        idx_X.append(idx)\n",
    "            for i in idx_X:\n",
    "                self.Y_pred[i] = node.leaf_val[0]\n",
    "        else:\n",
    "            Xl = X[X.loc[:, node.feature] == True]\n",
    "            Xr = X[X.loc[:, node.feature] == False]\n",
    "            self.ppart(Xl, node.left, mainX)\n",
    "            self.ppart(Xr, node.right, mainX)\n",
    "                \n",
    "    def score(self, Y):\n",
    "        if self.issparse:\n",
    "            equal = np.ravel(Y.toarray())== np.asarray(self.Y_pred)\n",
    "        else:\n",
    "            equal = Y == self.Y_pred\n",
    "        unique, counts = np.unique(equal, return_counts=True)\n",
    "        if len(unique) == 2:\n",
    "            if unique[0] == False:\n",
    "                return counts[0]/len(self.Y_pred)\n",
    "            else:\n",
    "                return counts[1]/len(self.Y_pred)\n",
    "        else:\n",
    "            if unique == True:\n",
    "                return 0\n",
    "        return 1\n",
    "\n",
    "    def graph(self):\n",
    "        self.all_nodes = []\n",
    "        self.all_edges = []\n",
    "        dot = graphviz.Digraph(comment='Decision tree')\n",
    "        if self.issparse:\n",
    "            self.gpart_sparse(self.node, None, words)\n",
    "        else:\n",
    "            self.gpart(self.node, None)\n",
    "        for i in self.all_nodes:\n",
    "            dot.node(str(i[0]), str(i[1]), shape='box')\n",
    "        for i in self.all_edges:\n",
    "            dot.edge(str(i[1]), str(i[0]))\n",
    "        return dot\n",
    "    \n",
    "    def gpart(self, node, parent):\n",
    "        node_data = ''\n",
    "        if node.feature != None:\n",
    "            node_data += 'feature:'+node.feature+'\\n'\n",
    "        if node.pi != None:\n",
    "            node_data += 'pi: '+''.join(np.array2string(np.around(node.pi[1], decimals=2)))+'\\n'\n",
    "        if node.leaf_val != None:\n",
    "            node_data += 'class: '+str(node.leaf_val[0])+'\\n'\n",
    "        node_data += 'samples = '+str(node.size)\n",
    "        self.all_nodes.append([node.idx, node_data])\n",
    "        if parent != None:\n",
    "            self.all_edges.append([node.idx, parent])\n",
    "        if node.leaf_val == None:\n",
    "            self.gpart(node.left, node.idx)\n",
    "            self.gpart(node.right, node.idx)\n",
    "            \n",
    "    def gpart_sparse(self, node, parent, words):\n",
    "        node_data = ''\n",
    "        node_data += 'idx='+str(node.idx)+'\\n samples = '+str(node.size)\n",
    "        if node.feature != None:\n",
    "            node_data += '\\n word: '+words[node.feature]\n",
    "        if node.leaf_val != None:\n",
    "            node_data += '\\n dec= '+str(node.leaf_val)\n",
    "        self.all_nodes.append([node.idx, node_data])\n",
    "        if parent != None:\n",
    "            self.all_edges.append([node.idx, parent])\n",
    "        if node.leaf_val == None:\n",
    "            self.gpart_sparse(node.left, node.idx, words)\n",
    "            self.gpart_sparse(node.right, node.idx, words)\n",
    "            \n",
    "    def get_params(self, deep=True): \n",
    "        return {\"stop_condition\": self.stop_condition, \"max_depth\": self.max_depth, \"max_n_nodes\": self.max_n_nodes}\n",
    "\n",
    "    def set_params(self, parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "                \n",
    "    def crossvalidation(self, X, Y, depth, n_splits, max_n_nodes, stop_condition):\n",
    "        score = []\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=4)\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            self.set_params({\"max_depth\": depth, \"max_n_nodes\": max_n_nodes, \"stop_condition\": stop_condition})\n",
    "            if isspmatrix(X):\n",
    "                X_train, X_test, y_train, y_test = X[train_index], X[test_index], Y[train_index], Y[test_index]\n",
    "                self.fit(X_train.tocsc(), y_train.tocsc())\n",
    "            else:\n",
    "                X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], \\\n",
    "                                                Y.iloc[train_index], Y.iloc[test_index]\n",
    "                self.fit(X_train, y_train)\n",
    "            self.predict(X_test)\n",
    "            score.append(self.score(y_test))\n",
    "        return score, y_test, self.Y_pred\n",
    "           \n",
    "    def roc(self):\n",
    "        pass\n",
    "    \n",
    "    def confusion_matrix(self, y_test, y_pred):\n",
    "        y_test_ = np.ravel(y_test.toarray())\n",
    "        y_pred_ = np.asarray(d.Y_pred)\n",
    "        unique, counts = np.unique(y_test_*10+y_pred_, return_counts=True)\n",
    "        TN = 0\n",
    "        FN = 0\n",
    "        FP = 0 \n",
    "        TP = 0\n",
    "        for ui, ci in zip(unique, counts):\n",
    "            if ui == 0:\n",
    "                TN = ci\n",
    "            elif ui == 1:\n",
    "                FP = ci\n",
    "            elif ui == 10:\n",
    "                FN = ci\n",
    "            else:\n",
    "                TP = ci\n",
    "        return TN, FN, FP, TP\n",
    "\n",
    "    def TPR_FPR(self, y_test, y_pred):\n",
    "        TN, FN, FP, TP = self.confusion_matrix(y_test, y_pred)\n",
    "        self.TPR.append(TP/(TP+FN))\n",
    "        self.FPR.append(FP/(FP+TN))\n",
    "        \n",
    "class Node():\n",
    "    def __init__(self, parent, used_features, depth, idx, size):\n",
    "        self.feature = None\n",
    "        self.used_features = used_features\n",
    "        self.pi = None\n",
    "        self.left=None\n",
    "        self.right=None\n",
    "        self.depth=depth\n",
    "        self.idx = idx\n",
    "        self.leaf_val = None\n",
    "        self.size = size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading zoo dataset, classification, tree visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoo_df = pd.read_csv('zoo.csv')\n",
    "zoo_df = zoo_df.drop(['animal'], axis=1)\n",
    "kappa_zoo = []\n",
    "X = zoo_df.drop(['type'], axis=1)\n",
    "X['legs'] = X['legs'].apply(lambda x: x == 4)\n",
    "Y = zoo_df['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33)\n",
    "\n",
    "d = DecisionTree()\n",
    "d.set_params({\"max_depth\": 7, \"max_n_nodes\":6, \"stop_condition\":\"depth\"})\n",
    "start_time = time.time()\n",
    "d.fit(X_train, y_train)\n",
    "print(\"FIT TIME:\", time.time() - start_time, \"s\")\n",
    "\n",
    "start_time = time.time()\n",
    "d.predict(X_test)\n",
    "print(\"PREDICT TIME:\", time.time() - start_time, \"s\")\n",
    "print(\"ERROR:\", d.score(y_test))\n",
    "\n",
    "dot = d.graph()\n",
    "dot.format = 'png'\n",
    "dot.view(filename='zoo', directory='./data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossvalidation (own implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "d = DecisionTree()\n",
    "\n",
    "d.crossvalidation(X, Y, 8, 4, 30, \"n_nodes\")\n",
    "print(\"TIME:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossvalidation (Sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "start = time.time()\n",
    "clf = DecisionTreeClassifier()\n",
    "gc = GridSearchCV(clf, {\"max_depth\": [8]},cv=4, verbose=0).fit(X, Y)\n",
    "print(\"TIME:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading RCV1 dataset, classification, tree visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv1 = fetch_rcv1()\n",
    "X = rcv1[\"data\"]\n",
    "y = rcv1.target[:, 87]\n",
    "X = X>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "with open('stem.termid.idf.map.txt', \"r\", encoding=\"utf8\") as reader:\n",
    "    for line in reader:\n",
    "        words.append(line.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "X_train = X_train.tocsc()\n",
    "y_train = y_train.tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DecisionTree()\n",
    "d.set_params({\"max_depth\": 5, \"max_n_nodes\":2, \"stop_condition\":\"depth\"})\n",
    "start_time = time.time()\n",
    "d.fit(X_train, y_train)\n",
    "print(\"FIT TIME:\", time.time() - start_time, \"s\")\n",
    "\n",
    "start_time = time.time()\n",
    "d.predict(X_test)\n",
    "print(\"PREDICT TIME:\", time.time() - start_time, \"s\")\n",
    "print(\"ERROR:\", d.score(y_test))\n",
    "\n",
    "dot = d.graph()\n",
    "dot.format = 'png'\n",
    "dot.view(filename='rcv1', directory='./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossvalidation (own implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "d = DecisionTree()\n",
    "start = time.time()\n",
    "d.crossvalidation(X, y, 3, 5, 3, \"depth\")\n",
    "print(\"TIME:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossvalidation (Sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "start = time.time()\n",
    "clf = DecisionTreeClassifier()\n",
    "gc = GridSearchCV(clf, {\"max_depth\": [3]}, cv=5, verbose=0).fit(X, y.todense())\n",
    "print(\"TIME:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DecisionTree()\n",
    "for i in range(2, 9):\n",
    "    d.set_params({\"max_depth\": i, \"max_n_nodes\":2, \"stop_condition\":\"depth\"})\n",
    "    start_time = time.time()\n",
    "    d.fit(X_train, y_train)\n",
    "    print(\"FIT TIME:\", time.time() - start_time, \"s\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    d.predict(X_test)\n",
    "    print(\"PREDICT TIME:\", time.time() - start_time, \"s\")\n",
    "    print(\"ERROR:\", d.score(y_test))\n",
    "\n",
    "    d.TPR_FPR(y_test, d.Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d.FPR, d.TPR)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
